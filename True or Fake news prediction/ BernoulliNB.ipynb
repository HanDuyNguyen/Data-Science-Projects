{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv(r\"train.csv\", usecols = [\"text\", \"target\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                 Just happened a terrible car crash\n",
       "1   2  Heard about #earthquake is different cities, s...\n",
       "2   3  there is a forest fire at spot pond, geese are...\n",
       "3   9           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(r\"test.csv\", usecols = [\"id\", \"text\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_names : text', 'col_names : target'], dtype='object')\n",
      "\n",
      "\n",
      "Data-dimensions: \t(7613, 2)\n",
      "\n",
      "\n",
      "Count the not-null values of each features: \n",
      "text      7613\n",
      "target    7613\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"col_names : \" + train_df.columns)\n",
    "print('\\n')\n",
    "print(\"Data-dimensions: \\t\" + str(train_df.shape))\n",
    "print('\\n')\n",
    "print(\"Count the not-null values of each features: \\n\" + str(train_df.notnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The training data has no null-value!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and removing duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dimension after checking  & removing duplication is:\t(7521, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop_duplicates(inplace = True)\n",
    "print(\"The new dimension after checking  & removing duplication is:\\t\" + str(train_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding two additional features Text length and Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_length</th>\n",
       "      <th>Numb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  Text_length  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1           69   \n",
       "1             Forest fire near La Ronge Sask. Canada       1           38   \n",
       "2  All residents asked to 'shelter in place' are ...       1          133   \n",
       "3  13,000 people receive #wildfires evacuation or...       1           65   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1           88   \n",
       "\n",
       "   Numb_words  \n",
       "0          13  \n",
       "1           7  \n",
       "2          22  \n",
       "3           8  \n",
       "4          16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Text_length'] = train_df['text'].str.len()\n",
    "train_df['Numb_words'] = train_df['text'].str.split().map(lambda x: len(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Text_length</th>\n",
       "      <th>Numb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3258</td>\n",
       "      <td>10861</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3259</td>\n",
       "      <td>10865</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>10868</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3261</td>\n",
       "      <td>10874</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3262</td>\n",
       "      <td>10875</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  Text_length  \\\n",
       "3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...           55   \n",
       "3259  10865  Storm in RI worse than last hurricane. My city...          139   \n",
       "3260  10868  Green Line derailment in Chicago http://t.co/U...           55   \n",
       "3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...           65   \n",
       "3262  10875  #CityofCalgary has activated its Municipal Eme...           68   \n",
       "\n",
       "      Numb_words  \n",
       "3258           8  \n",
       "3259          23  \n",
       "3260           6  \n",
       "3261           7  \n",
       "3262           8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Text_length'] = test_df['text'].str.len()\n",
    "test_df['Numb_words'] = test_df['text'].str.split().map(lambda x: len(x))\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process_text(str_input):\n",
    "    ## 1. Remove url_link\n",
    "    remove_url = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', str_input)\n",
    "    \n",
    "    ## 2. Remove html_link\n",
    "    remove_html = re.compile(r'<.*?>').sub(r'', remove_url)\n",
    "    \n",
    "    ## 3. Remove Emojis\n",
    "    remove_emo = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE).sub(r'', remove_html)\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", remove_emo).lower().split()    \n",
    "        \n",
    "    ## 4. spell_correction\n",
    "    # spell = SpellChecker()\n",
    "    # words = [spell.correction(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#text_process = CountVectorizer(analyzer = process_text).fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5264, 13887), (2257, 13887), (3263, 13887))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = train_df.target.to_numpy()\n",
    "X_train_df = train_df[['text', 'Text_length', 'Numb_words']]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## Set test_size = 0.3\n",
    "test_size = 0.3\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=test_size, \n",
    "                                                    stratify = y_train_df, random_state = 42)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = process_text)\n",
    "\n",
    "tfidf_train = tfidf_vect.fit(X_train['text']).transform(X_train['text']) \n",
    "tfidf_test = tfidf_vect.fit(X_train['text']).transform(X_test['text'])\n",
    "tfidf_test_df = tfidf_vect.fit(X_train['text']).transform(test_df['text'])\n",
    "\n",
    "X_train_vect = pd.concat([\n",
    "                            X_train[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_train.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "X_test_vect = pd.concat([\n",
    "                            X_test[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_test.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "#X_test_df_vect.shape, X_test_vect.shape, y_train.shape\n",
    "tfidf_train.shape, tfidf_test.shape, tfidf_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf',  BernoulliNB(SelectPercentile(percentile = 97)))\n",
    "                   ])\n",
    "clf.named_steps['clf'].set_params(alpha=1.0, fit_prior=False)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.33%\n",
      "Testing_Accuracy: 79.40%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      1295\n",
      "           1       0.83      0.65      0.73       962\n",
      "\n",
      "    accuracy                           0.79      2257\n",
      "   macro avg       0.80      0.77      0.78      2257\n",
      "weighted avg       0.80      0.79      0.79      2257\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1171  124]\n",
      " [ 341  621]]\n",
      "F-measure = 83.43%.\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))\n",
    "\n",
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]\n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "\n",
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df_vect = pd.concat([\n",
    "                            test_df[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_test_df.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "predicts = clf.predict(X_test_df_vect)\n",
    "predicts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
